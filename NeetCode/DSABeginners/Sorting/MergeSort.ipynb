{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge sort is an extremely common sorting algorithm that is used by many programming languages as apart of their standard library.\n",
    "\n",
    "The concept behind it is very simple. Keep splitting the array into halves until the subarrays hit a size of one. Then recursively sort the subarrays by merging two subarrays at a time. The final array will be fully sorted.\n",
    "\n",
    "This is a technique that is known as divide and conquer. We divide the problem into smaller subproblems, solve them and then combine the solutions to get the final answer.\n",
    "\n",
    "    This is two-branch recursion, similar to the fibonacci sequence. \n",
    "\n",
    "Implementation\n",
    "\n",
    "Let's take an array of size 55 as an example, [3,2,4,1,6]. We want to sort it in an increasing, or non-decreasing order if we had duplicates. We will be splitting the array like the following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Implementation of MergeSort\n",
    "def mergeSort(arr, s, e):\n",
    "    if e - s + 1 <= 1:\n",
    "        return arr\n",
    "\n",
    "    # The middle index of the array\n",
    "    m = (s + e) // 2\n",
    "\n",
    "    # Sort the left half\n",
    "    mergeSort(arr, s, m)\n",
    "\n",
    "    # Sort the right half\n",
    "    mergeSort(arr, m + 1, e)\n",
    "\n",
    "    # Merge sorted halfs\n",
    "    merge(arr, s, m, e)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "# Merge in-place\n",
    "def merge(arr, s, m, e):\n",
    "    # Copy the sorted left & right halfs to temp arrays\n",
    "    L = arr[s: m + 1]\n",
    "    R = arr[m + 1: e + 1]\n",
    "\n",
    "    i = 0 # index for L\n",
    "    j = 0 # index for R\n",
    "    k = s # index for arr\n",
    "\n",
    "    # Merge the two sorted halfs into the original array\n",
    "    while i < len(L) and j < len(R):\n",
    "        if L[i] <= R[j]:\n",
    "            arr[k] = L[i]\n",
    "            i += 1\n",
    "        else:\n",
    "            arr[k] = R[j]\n",
    "            j += 1\n",
    "        k += 1\n",
    "\n",
    "    # One of the halfs will have elements remaining\n",
    "    while i < len(L):\n",
    "        arr[k] = L[i]\n",
    "        i += 1\n",
    "        k += 1\n",
    "    while j < len(R):\n",
    "        arr[k] = R[j]\n",
    "        j += 1\n",
    "        k += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If nn is the length of our array at any given level, our subarrays in the next level have a length n/2n/2.\n",
    "\n",
    "From our example above, we go from n=4n=4 to n=2n=2 to n=1n=1 which is the base case. The question here is how many times can we divide nn by 22 until we hit the base case. This would look like n/2x=1n/2x=1 where xx is the number of times we need to divide nn by two until we get to one.\n",
    "\n",
    "n/2x=1n/2x=1\n",
    "\n",
    "    Isolate nn by multiplying both sides by 2x2x \n",
    "\n",
    "n=2xn=2x\n",
    "\n",
    "    To solve for xx, take loglog of both sides \n",
    "\n",
    "log n=log2xlog n=log2x\n",
    "\n",
    "    According to loglog rules, we can simplify this to: \n",
    "\n",
    "log n=x log 2log n=x log 2\n",
    "\n",
    "    log 2log 2 is basically asking 22 to the power of what is equal to 22 i.e . 2?=22?=2, which is just 11 \n",
    "\n",
    "log n=xlog n=x\n",
    "\n",
    "Thus, the final answer is x=log nx=log n.\n",
    "\n",
    "This means we have log nlog n levels in our recursion tree. But what is the cost of each level?\n",
    "\n",
    "This is dependent on the merge() function. Merge will take nn steps because at any level of the tree, we have nn elements to compare and sort, where nn is the length of the original array.\n",
    "\n",
    "To get the final time complexity we multiply the number of levels in the recursion tree by the cost of each level.\n",
    "\n",
    "This results in a O(n log n)O(n log n) time complexity.\n",
    "Space\n",
    "\n",
    "The height of the recursion tree is log nlog n and at each level. At any given level, we have nn elements to sort, which we will allocate temporary arrays for in the merge() function.\n",
    "\n",
    "To get the total space complexity we sum both terms and get O(n +log n)O(n +log n), which simplifies to O(n)O(n).\n",
    "\n",
    "The reason we sum rather than multiply is because not all of the temporary arrays will be allocated at the same time, but rather one at a time.\n",
    "Stability\n",
    "\n",
    "Merge Sort proves to be a stable algorithm because if we have a pair of duplicates, say, 77, the 77 in the left subarray will always end up in the merged array first followed by the 77 in the right subarray. This is because when we compare the ith element in the left subarray to the jth element in the right subarray for equality, we pick the one in the left subarray, maintaining the relative order. Recall the following pseudocode from the merge() subroutine.\n",
    "\n",
    "if leftSubarray[i] <= rightSubarray[j]:\n",
    "    arr[k] = leftSubarray[i]\n",
    "    i += 1\n",
    "\n",
    "Closing Notes\n",
    "\n",
    "So how does merge sort stack up with insertion sort? In the worst case scenario, insertion sort runs in O(n2)O(n2) with merge sort running in O(n log n)O(n log n) in the worst, average and best case scenarios, making merge sort superior.\n",
    "\n",
    "The only time where insertion sort might be preferred is when the array has fewer elements and is already, or nearly sorted as it would skip the swapping."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
